{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione - k-nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import moduli per la manipolazione dei dataframe\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modulo di classificazione da sklearn-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modulo grafica\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimozione messaggi di warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello di classificazione\n",
    "# Numero di 'vicini' = 3\n",
    "knn = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione array casuale di 6 coppie di valori da 1 a 5. Gruppo 0.\n",
    "# np.random.seed(0)\n",
    "x = np.array(np.random.randint(1, 6, size = 12))\n",
    "x = x.reshape(6,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione array casuale di 6 coppie di valori da 6 a 11. Gruppo 1.\n",
    "y = np.array(np.random.randint(6, 12, size = 12))\n",
    "y = y.reshape(6,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unione in un unico oggetto \n",
    "z = np.vstack((x, y))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione fattore di classificazione\n",
    "cl = np.array([0,0,0,0,0,0,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adattiamo il modello di classificazione a questi dati\n",
    "knn.fit(z, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0 = []\n",
    "y0 = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "for i in x:\n",
    "    x0.append(i[0])\n",
    "    y0.append(i[1])\n",
    "for i in y:\n",
    "    x1.append(i[0])\n",
    "    y1.append(i[1])\n",
    "   \n",
    "plt.plot(x0, y0, 'ro', color = \"red\")\n",
    "plt.plot(x1, y1, 'ro', color = \"green\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = []\n",
    "y0 = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "for i in x:\n",
    "    x0.append(i[0])\n",
    "    y0.append(i[1])\n",
    "for i in y:\n",
    "    x1.append(i[0])\n",
    "    y1.append(i[1])\n",
    "   \n",
    "plt.plot(x0, y0, 'ro', color = \"red\")\n",
    "plt.plot(x1, y1, 'ro', color = \"green\")\n",
    "\n",
    "new = ([[4.5,6]], [[1,4]], [[7,7]], [[8,12]])\n",
    "for n in new:\n",
    "    print (knn.predict(n) )\n",
    "    if knn.predict(n) == 1: \n",
    "        c=\"green\"\n",
    "    else:\n",
    "        c=\"red\"\n",
    "    plt.plot(n[0][0], n[0][1], 'ro', color = c, markersize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione - esempio su un dataset più grande "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import moduli per la manipolazione dei dataframe\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modulo di classificazione da sklearn-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 'iris', 150 casi di fiori classificati sotto tre diverse famiglie (setosa, versicolor, virginica).\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il dataset 'iris' è composto da 4 variabili di attributi (tutti in cm) + una variabile della classe.   \n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', \"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello di classificazione\n",
    "# Numero di 'vicini' = 3\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un dataset con i 4 attributi\n",
    "df2 = df.iloc[:, 0:4]\n",
    "df2.shape\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridimensionamento delle variabili con valori tra 0 e 1.\n",
    "# Non necessario in questo caso essendo tutte le variabili in cm.\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(df2) # numpy.ndarray\n",
    "df_scaled = pd.DataFrame(scaled)\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di oggetti di training e di oggetti di test partendo dalle due parti del dataset.\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_scaled, df['Class'], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adattiamo il modello di classificazione ai dati di train\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione della predizione dall'oggetto di test.\n",
    "pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice di confusione. Nella diagonale i casi classificati correttamente.\n",
    "# Le previsioni sono rappresentate dalle colonne, i valori effettivi dalle righe.\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisione\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricerca del numero dei neighbors ottimale per impostare il modello nel modo migliore.\n",
    "err = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    err.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(range(1, 10), err, color='green', linestyle='dotted', marker='o',\n",
    "         markerfacecolor='red', markersize=12)\n",
    "plt.xlabel('Numero di k')\n",
    "plt.ylabel('Tasso di errore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiamo quindi il numero di k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
